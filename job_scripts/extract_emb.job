#!/bin/bash
#SBATCH --job-name=blip3o_distributed_extraction_fixed
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=4
#SBATCH --ntasks=4
#SBATCH --cpus-per-task=8
#SBATCH --mem=120G
#SBATCH --time=6:00:00
#SBATCH --output=./slurm_out/blip3o_distributed_extraction_fixed_%j.out
#SBATCH --error=./slurm_out/blip3o_distributed_extraction_fixed_%j.err

# =============================================================================
# FIXED BLIP3-o Multi-GPU Embedding Extraction
# Distributes TAR file processing across multiple GPUs with error handling
# =============================================================================

echo "🚀 FIXED BLIP3-o Multi-GPU Embedding Extraction"
echo "=========================================="
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "GPUs: ${SLURM_GPUS_ON_NODE}"
echo "CPUs per task: ${SLURM_CPUS_PER_TASK}"
echo "Memory: ${SLURM_MEM_PER_NODE}MB"
echo "=========================================="

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Setup BLIP3-o workspace
export SCRATCH_SHARED="/scratch-shared"
export BLIP3O_USER=$(whoami)
export BLIP3O_JOB_ID=${SLURM_JOB_ID}

# Set up structured directories
export BLIP3O_WORKSPACE="/scratch-shared/${BLIP3O_USER}/blip3o_workspace"
export BLIP3O_EMBEDDINGS="${BLIP3O_WORKSPACE}/embeddings"
export BLIP3O_CHECKPOINTS="${BLIP3O_WORKSPACE}/checkpoints"
export BLIP3O_DATASETS="${BLIP3O_WORKSPACE}/datasets"
export BLIP3O_LOGS="${BLIP3O_WORKSPACE}/logs"

# Job temp directory
export BLIP3O_JOB_TEMP="/scratch-local/${BLIP3O_USER}.${BLIP3O_JOB_ID}/blip3o_job_${BLIP3O_JOB_ID}"
export BLIP3O_CACHE="${BLIP3O_JOB_TEMP}/cache"

# Create directories
mkdir -p "${BLIP3O_WORKSPACE}"/{datasets,embeddings,checkpoints,logs,metadata}
mkdir -p "${BLIP3O_JOB_TEMP}"/{cache,working,temp_checkpoints}

# Model cache (redirected to job temp to avoid home quota)
export TORCH_HOME="${BLIP3O_CACHE}/torch"
export HF_HOME="${BLIP3O_CACHE}/huggingface"
export TRANSFORMERS_CACHE="${BLIP3O_CACHE}/transformers"

# Create cache subdirectories
mkdir -p "${TORCH_HOME}" "${HF_HOME}" "${TRANSFORMERS_CACHE}"

echo "🗂️  BLIP3-o workspace ready:"
echo "   Persistent: $BLIP3O_WORKSPACE"
echo "   Job temp:   $BLIP3O_JOB_TEMP"
echo "   Datasets:   $BLIP3O_DATASETS"
echo "   Embeddings: $BLIP3O_EMBEDDINGS"

# Extraction configuration (can be overridden by command line arguments)
WORLD_SIZE=${SLURM_GPUS_ON_NODE}
MASTER_PORT="12356"  # Different from training port
BATCH_SIZE_PER_GPU=32
INCLUDE_CLS=false
MAX_SHARDS=50
MAX_RETRIES=3

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --include_cls)
            INCLUDE_CLS=true
            shift
            ;;
        --batch_size)
            BATCH_SIZE_PER_GPU="$2"
            shift 2
            ;;
        --max_shards)
            MAX_SHARDS="$2"
            shift 2
            ;;
        --world_size)
            WORLD_SIZE="$2"
            shift 2
            ;;
        --max_retries)
            MAX_RETRIES="$2"
            shift 2
            ;;
        *)
            echo "Unknown option: $1"
            shift
            ;;
    esac
done

# Determine extraction mode
if [ "$INCLUDE_CLS" = true ]; then
    TARGET_TOKENS=257
    MODE_NAME="CLS+Patches"
    MODE_SUFFIX="cls_patch"
else
    TARGET_TOKENS=256
    MODE_NAME="Patches only"
    MODE_SUFFIX="patch_only"
fi

# Set output directory
OUTPUT_DIR="${BLIP3O_EMBEDDINGS}/${MODE_SUFFIX}_${TARGET_TOKENS}_tokens"

# Create output directories
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

echo ""
echo "⚙️ FIXED Multi-GPU Extraction Configuration:"
echo "====================================="
echo "Mode: $MODE_NAME ($TARGET_TOKENS tokens)"
echo "Output: $OUTPUT_DIR"
echo "GPUs: $WORLD_SIZE"
echo "Batch size per GPU: $BATCH_SIZE_PER_GPU"
echo "Total effective batch size: $((BATCH_SIZE_PER_GPU * WORLD_SIZE))"
echo "Max shards: $MAX_SHARDS"
echo "Max retries per shard: $MAX_RETRIES"
echo "Master port: $MASTER_PORT"
echo ""
echo "🔧 FIXES APPLIED:"
echo "  • WebDataset nodesplitter for multi-GPU support"
echo "  • Better error handling with retry mechanism" 
echo "  • Skip corrupted shards instead of failing completely"
echo "  • Robust consolidation with failure tracking"
echo ""
echo "🎯 Expected Benefits:"
echo "  • ~${WORLD_SIZE}x extraction speedup"
echo "  • Parallel TAR file processing"
echo "  • Better GPU utilization"
echo "  • Graceful handling of corrupted shards"
echo "  • Faster preprocessing for large datasets"
echo ""

# Check for dataset files
if [ ! -d "$BLIP3O_DATASETS" ]; then
    echo "❌ Datasets directory not found: $BLIP3O_DATASETS"
    echo ""
    echo "💡 To download datasets:"
    echo "  python src/data_hand/download_data.py --shards 0 1 2 3 4 5 6 7 8 9"
    echo "  # Make sure to place downloaded TAR files in: $BLIP3O_DATASETS"
    exit 1
fi

# Count available TAR files
TAR_COUNT=$(find "$BLIP3O_DATASETS" -name "*.tar" | wc -l)
echo "✅ Found $TAR_COUNT TAR files in datasets directory"

if [ $TAR_COUNT -eq 0 ]; then
    echo "❌ No TAR files found in datasets directory!"
    echo "Available files:"
    ls -la "$BLIP3O_DATASETS/" 2>/dev/null || echo "Directory empty"
    exit 1
fi

if [ $TAR_COUNT -lt $MAX_SHARDS ]; then
    echo "⚠️ Only $TAR_COUNT TAR files available (requested $MAX_SHARDS)"
    MAX_SHARDS=$TAR_COUNT
    echo "   Adjusted to use $MAX_SHARDS shards"
fi

echo "✅ FIXED Multi-GPU extraction script ready"

echo ""
echo "🚀 Starting FIXED Multi-GPU Embedding Extraction..."
echo "=============================================="
echo "🎯 Extraction Strategy:"
echo "  • Distribute TAR files across $WORLD_SIZE GPUs"
echo "  • Each GPU processes assigned files independently"
echo "  • Skip corrupted shards gracefully"
echo "  • Retry failed shards up to $MAX_RETRIES times"
echo "  • Coordinated saving to prevent conflicts"
echo "  • Automatic consolidation after extraction"
echo ""
echo "📊 Processing Details:"
echo "  • TAR files: $TAR_COUNT available, using $MAX_SHARDS"
echo "  • Files per GPU: ~$((MAX_SHARDS / WORLD_SIZE))"
echo "  • Batch processing: $BATCH_SIZE_PER_GPU per GPU"
echo "  • Output format: ${MODE_SUFFIX}_${TARGET_TOKENS}_tokens"
echo "  • Error handling: Skip corrupted, retry failed"
echo ""

# Build extraction command with all fixes
EXTRACTION_CMD="python src/modules/extract_embeddings_distributed.py \
    --world_size $WORLD_SIZE \
    --master_port $MASTER_PORT \
    --batch_size $BATCH_SIZE_PER_GPU \
    --max_shards $MAX_SHARDS \
    --max_retries $MAX_RETRIES"

# Add CLS token option if specified
if [ "$INCLUDE_CLS" = true ]; then
    EXTRACTION_CMD="$EXTRACTION_CMD --include_cls"
fi

echo "Executing FIXED multi-GPU extraction command:"
echo "$EXTRACTION_CMD"
echo ""

# Launch distributed extraction
eval $EXTRACTION_CMD

EXTRACTION_EXIT_CODE=$?

echo ""
echo "=============================================="
echo "📊 FIXED Multi-GPU Extraction Results"
echo "=============================================="

if [ $EXTRACTION_EXIT_CODE -eq 0 ]; then
    echo "✅ FIXED Multi-GPU embedding extraction completed successfully!"
    
    echo ""
    echo "📋 Extraction Summary:"
    echo "===================="
    
    # Check for output files
    echo ""
    echo "📋 Generated Files:"
    echo "=================="
    
    # Check for consolidated files
    CONSOLIDATED_FILES=$(find "$OUTPUT_DIR" -name "embeddings_shard_*_${MODE_SUFFIX}.pkl" | wc -l)
    if [ $CONSOLIDATED_FILES -gt 0 ]; then
        echo "✅ Found $CONSOLIDATED_FILES consolidated embedding files"
        
        # Calculate total size
        TOTAL_SIZE=$(du -sh "$OUTPUT_DIR" 2>/dev/null | cut -f1)
        echo "✅ Total size: $TOTAL_SIZE"
        
        # Check manifest
        MANIFEST_FILE="${OUTPUT_DIR}/embeddings_manifest.json"
        if [ -f "$MANIFEST_FILE" ]; then
            echo "✅ Manifest file: $MANIFEST_FILE"
            
            # Extract summary from manifest
            python -c "
import json
import sys
try:
    with open('$MANIFEST_FILE', 'r') as f:
        manifest = json.load(f)
    
    extraction_info = manifest.get('extraction_info', {})
    consolidation = manifest.get('consolidation_results', {})
    
    print(f'📊 FIXED Multi-GPU Extraction Summary:')
    print(f'   GPUs used: {extraction_info.get(\"world_size\", \"unknown\")}')
    print(f'   Extraction time: {extraction_info.get(\"extraction_time_seconds\", 0):.1f}s')
    print(f'   Total shards attempted: $(echo '$MAX_SHARDS')')
    print(f'   Successful shards: {consolidation.get(\"consolidated_shards\", \"unknown\")}')
    print(f'   Failed shards: {len(consolidation.get(\"failed_shards\", []))}')
    print(f'   Total samples: {consolidation.get(\"total_samples\", \"unknown\"):,}')
    print(f'   Success rate: {consolidation.get(\"success_rate\", 0)*100:.1f}%')
    print(f'   Mode: $MODE_NAME ($TARGET_TOKENS tokens)')
    
    # Show failed shards if any
    failed_shards = consolidation.get('failed_shards', [])
    if failed_shards:
        print(f'   ⚠️ Failed shards: {failed_shards}')
        print(f'   Note: Training can continue with successful shards')
    
    # Calculate speedup
    world_size = extraction_info.get('world_size', 1)
    extraction_time = extraction_info.get('extraction_time_seconds', 0)
    if world_size > 1 and extraction_time > 0:
        theoretical_speedup = world_size
        print(f'   Theoretical speedup: ~{theoretical_speedup:.1f}x')
    
except Exception as e:
    print(f'Could not parse manifest: {e}')
    sys.exit(1)
"
        fi
        
        echo ""
        echo "🎉 SUCCESS: FIXED Multi-GPU extraction completed!"
        echo ""
        echo "💡 Next step - Start distributed training:"
        echo "sbatch job_scripts/train_blip3o_fsdp.job --embeddings_dir $OUTPUT_DIR"
        echo ""
        echo "Or manually:"
        echo "torchrun --nproc_per_node=$WORLD_SIZE train_dit_distributed.py \\"
        echo "  --chunked_embeddings_dir $OUTPUT_DIR \\"
        echo "  --output_dir ./checkpoints \\"
        echo "  --distributed --world_size $WORLD_SIZE"
        
    else
        echo "⚠️ No consolidated files found - check for partial results"
        echo "Files in output directory:"
        ls -la "$OUTPUT_DIR" 2>/dev/null | head -10
        
        # Check for GPU-specific files that might need manual consolidation
        GPU_FILES=$(find "$OUTPUT_DIR" -name "*_gpu*.pkl" | wc -l)
        if [ $GPU_FILES -gt 0 ]; then
            echo "Found $GPU_FILES GPU-specific files that may need consolidation"
        fi
    fi
    
    # Show extraction benefits achieved
    echo ""
    echo "⚡ FIXED Multi-GPU Extraction Benefits Achieved:"
    echo "  • Parallel TAR file processing across $WORLD_SIZE GPUs"
    echo "  • ~${WORLD_SIZE}x theoretical speedup"
    echo "  • Better GPU utilization"
    echo "  • Graceful handling of corrupted shards"
    echo "  • Skip failed shards instead of crashing"
    echo "  • Automatic consolidation and cleanup"
    echo "  • Ready for distributed training"
    echo "  • WebDataset nodesplitter fixes applied"
    
else
    echo "❌ FAILED: FIXED Multi-GPU extraction exit code $EXTRACTION_EXIT_CODE"
    echo ""
    echo "💡 Troubleshooting:"
    echo "  • Check log files in ./slurm_out/ for detailed error messages"
    echo "  • Verify TAR files are accessible and not corrupted"
    echo "  • Check GPU memory usage - try smaller batch size if OOM"
    echo "  • Verify WebDataset installation and compatibility"
    echo "  • Check available disk space for output files"
    echo ""
    echo "🔧 Recovery options:"
    echo "  • Reduce batch size: --batch_size 16"
    echo "  • Use fewer shards: --max_shards 5"
    echo "  • Increase retry count: --max_retries 5"
    echo "  • Check intermediate files for partial completion"
    echo "  • Try single-GPU extraction as fallback"
    echo ""
    echo "🔍 Quick checks:"
    echo "  • GPU memory: nvidia-smi"
    echo "  • Disk space: df -h"
    echo "  • TAR files: ls -la $BLIP3O_DATASETS/*.tar"
    
    # Show any intermediate files that might exist
    echo ""
    echo "🔍 Checking for intermediate files..."
    INTERMEDIATE_FILES=$(find "$OUTPUT_DIR" -name "*_gpu*.pkl" 2>/dev/null | wc -l)
    if [ $INTERMEDIATE_FILES -gt 0 ]; then
        echo "Found $INTERMEDIATE_FILES intermediate files:"
        find "$OUTPUT_DIR" -name "*_gpu*.pkl" 2>/dev/null | head -3
        echo ""
        echo "💡 You can try to consolidate these files manually or re-run extraction"
    else
        echo "No intermediate GPU-specific files found"
    fi
    
    # Show failure markers
    FAILURE_MARKERS=$(find "$OUTPUT_DIR" -name "failed_shard_*.txt" 2>/dev/null | wc -l)
    if [ $FAILURE_MARKERS -gt 0 ]; then
        echo "Found $FAILURE_MARKERS failure markers - check these files for details"
    fi
fi

echo ""
echo "📊 Multi-GPU Resource Usage Summary:"
nvidia-smi --query-gpu=name,memory.total,memory.used,utilization.gpu --format=csv,noheader,nounits | \
    awk 'BEGIN{print "GPU | Total Memory | Used Memory | Utilization"} {printf "%s | %s MB | %s MB | %s%%\n", $1, $2, $3, $4}'

echo ""
echo "🏁 Job completed at $(date)"
echo "Total job time: $(echo "scale=2; ($(date +%s) - $SECONDS) / 3600" | bc -l) hours"
echo ""
echo "📚 FIXED MULTI-GPU EXTRACTION SUMMARY:"
echo "This job extracted CLIP and EVA-CLIP embeddings from TAR files"
echo "using multiple GPUs for parallel processing with improved error handling."
echo ""
echo "Benefits of FIXED multi-GPU extraction:"
echo "• Parallel processing across $WORLD_SIZE GPUs"
echo "• WebDataset nodesplitter fixes for distributed processing"
echo "• Graceful handling of corrupted shards"
echo "• Skip failed shards instead of crashing completely"
echo "• Better resource utilization"
echo "• Coordinated output management"
echo "• Scalable to more GPUs and larger datasets"
echo "• Retry mechanism for temporary failures"
echo ""
echo "The extracted embeddings are ready for distributed BLIP3-o training"
echo "using FSDP (Fully Sharded Data Parallel)."
echo "=============================================="

exit $EXTRACTION_EXIT_CODE