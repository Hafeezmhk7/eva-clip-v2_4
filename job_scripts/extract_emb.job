#!/bin/bash
#SBATCH --job-name=blip3o_multi_gpu
#SBATCH --partition=gpu_h100
#SBATCH --nodes=1
#SBATCH --gpus=3
#SBATCH --ntasks=3
#SBATCH --cpus-per-task=8
#SBATCH --mem=250G
#SBATCH --time=8:00:00
#SBATCH --output=./slurm_out/blip3o_multi_gpu_%j.out
#SBATCH --error=./slurm_out/blip3o_multi_gpu_%j.err

# =============================================================================
# BLIP3-o Multi-GPU Embedding Extraction
# =============================================================================

echo "üöÄ BLIP3-o Multi-GPU Embedding Extraction"
echo "Job ID: ${SLURM_JOB_ID}"
echo "Node: $(hostname)"
echo "Time: $(date)"
echo "GPUs: ${SLURM_GPUS_ON_NODE}"

cd $SLURM_SUBMIT_DIR

# Setup environment
module purge
module load 2024
module load Miniconda3/24.7.1-0
module load CUDA/12.6.0
source activate eva_clip_env

# Setup workspace directories
export SCRATCH_SHARED="/scratch-shared"
export BLIP3O_USER=$(whoami)
export BLIP3O_JOB_ID=${SLURM_JOB_ID}

export BLIP3O_WORKSPACE="/scratch-shared/${BLIP3O_USER}/blip3o_workspace"
export BLIP3O_EMBEDDINGS="${BLIP3O_WORKSPACE}/embeddings"
export BLIP3O_CHECKPOINTS="${BLIP3O_WORKSPACE}/checkpoints"
export BLIP3O_DATASETS="${BLIP3O_WORKSPACE}/datasets"
export BLIP3O_LOGS="${BLIP3O_WORKSPACE}/logs"

export BLIP3O_JOB_TEMP="/scratch-local/${BLIP3O_USER}.${BLIP3O_JOB_ID}/blip3o_job_${BLIP3O_JOB_ID}"
export BLIP3O_CACHE="${BLIP3O_JOB_TEMP}/cache"

# Create directories
mkdir -p "${BLIP3O_WORKSPACE}"/{datasets,embeddings,checkpoints,logs,metadata}
mkdir -p "${BLIP3O_JOB_TEMP}"/{cache,working,temp_checkpoints}

# Model cache (redirected to job temp)
export TORCH_HOME="${BLIP3O_CACHE}/torch"
export HF_HOME="${BLIP3O_CACHE}/huggingface"
export TRANSFORMERS_CACHE="${BLIP3O_CACHE}/transformers"
export WANDB_DIR="${BLIP3O_LOGS}/wandb"
export HUGGINGFACE_HUB_CACHE="${BLIP3O_CACHE}/huggingface/hub"
export HF_DATASETS_CACHE="${BLIP3O_CACHE}/datasets"

mkdir -p "${TORCH_HOME}" "${HF_HOME}" "${TRANSFORMERS_CACHE}" "${WANDB_DIR}" "${HUGGINGFACE_HUB_CACHE}" "${HF_DATASETS_CACHE}"

echo "Workspace: $BLIP3O_WORKSPACE"
echo "Job temp: $BLIP3O_JOB_TEMP"

# Configuration
WORLD_SIZE=${SLURM_GPUS_ON_NODE}
MASTER_PORT="12361"
BATCH_SIZE=128
MAX_SHARDS=20
INCLUDE_CLS=false

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        --include_cls)
            INCLUDE_CLS=true
            shift
            ;;
        --batch_size)
            BATCH_SIZE="$2"
            shift 2
            ;;
        --max_shards)
            MAX_SHARDS="$2"
            shift 2
            ;;
        --world_size)
            WORLD_SIZE="$2"
            shift 2
            ;;
        *)
            echo "Unknown option: $1"
            shift
            ;;
    esac
done

# Determine extraction mode
if [ "$INCLUDE_CLS" = true ]; then
    TARGET_TOKENS=257
    MODE_NAME="CLS+Patches"
    MODE_SUFFIX="cls_patch"
else
    TARGET_TOKENS=256
    MODE_NAME="Patches only"
    MODE_SUFFIX="patch_only"
fi

OUTPUT_DIR="${BLIP3O_EMBEDDINGS}/${MODE_SUFFIX}_${TARGET_TOKENS}_tokens"
mkdir -p "${OUTPUT_DIR}"
mkdir -p ./slurm_out

echo "Mode: $MODE_NAME ($TARGET_TOKENS tokens)"
echo "Output: $OUTPUT_DIR"
echo "GPUs: $WORLD_SIZE"
echo "Batch size per GPU: $BATCH_SIZE"
echo "Max shards: $MAX_SHARDS"

# Validate extraction script
EXTRACTION_SCRIPT="src/modules/extract_embeddings_unified.py"
if [ ! -f "$EXTRACTION_SCRIPT" ]; then
    echo "‚ùå Extraction script not found: $EXTRACTION_SCRIPT"
    exit 1
fi

# Check for dataset files
if [ ! -d "$BLIP3O_DATASETS" ]; then
    echo "‚ùå Datasets directory not found: $BLIP3O_DATASETS"
    echo "To download datasets:"
    echo "  python src/data_hand/download_data.py --shards 0 1 2 3 4 5 6 7 8 9"
    exit 1
fi

TAR_COUNT=$(find "$BLIP3O_DATASETS" -name "*.tar" | wc -l)
echo "Found $TAR_COUNT TAR files in datasets directory"

if [ $TAR_COUNT -eq 0 ]; then
    echo "‚ùå No TAR files found in datasets directory!"
    exit 1
fi

if [ $TAR_COUNT -lt $MAX_SHARDS ]; then
    MAX_SHARDS=$TAR_COUNT
    echo "Adjusted to use $MAX_SHARDS shards"
fi

# Display GPU information
echo "GPU Information:"
nvidia-smi --query-gpu=index,name,memory.total,memory.free --format=csv,noheader

# Build extraction command
EXTRACTION_CMD="python $EXTRACTION_SCRIPT \
    --world_size $WORLD_SIZE \
    --master_port $MASTER_PORT \
    --batch_size $BATCH_SIZE \
    --max_shards $MAX_SHARDS"

if [ "$INCLUDE_CLS" = true ]; then
    EXTRACTION_CMD="$EXTRACTION_CMD --include_cls"
fi

echo "Starting extraction:"
echo "$EXTRACTION_CMD"
echo "Started at: $(date)"

# Launch extraction
eval $EXTRACTION_CMD

EXTRACTION_EXIT_CODE=$?

echo "Completed at: $(date)"

if [ $EXTRACTION_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ Multi-GPU embedding extraction completed successfully!"
    
    # Check for output files
    CONSOLIDATED_FILES=$(find "$OUTPUT_DIR" -name "embeddings_shard_*_${MODE_SUFFIX}.pkl" | wc -l)
    if [ $CONSOLIDATED_FILES -gt 0 ]; then
        echo "‚úÖ Found $CONSOLIDATED_FILES consolidated embedding files"
        
        TOTAL_SIZE=$(du -sh "$OUTPUT_DIR" 2>/dev/null | cut -f1)
        echo "‚úÖ Total size: $TOTAL_SIZE"
        
        SUCCESS_RATE=$(echo "scale=1; $CONSOLIDATED_FILES * 100 / $MAX_SHARDS" | bc -l 2>/dev/null || echo "N/A")
        echo "‚úÖ Success rate: $SUCCESS_RATE% ($CONSOLIDATED_FILES/$MAX_SHARDS shards)"
        
        # Check manifest
        MANIFEST_FILE="${OUTPUT_DIR}/embeddings_manifest.json"
        if [ -f "$MANIFEST_FILE" ]; then
            echo "‚úÖ Manifest file: $MANIFEST_FILE"
        fi
        
        echo "üéâ EXTRACTION SUCCESS!"
        echo "Next steps:"
        echo "torchrun --nproc_per_node=$WORLD_SIZE train_dit_distributed.py \\"
        echo "  --chunked_embeddings_dir $OUTPUT_DIR \\"
        echo "  --distributed --world_size $WORLD_SIZE"
        
    else
        echo "‚ö†Ô∏è No consolidated files found"
        echo "Files in output directory:"
        ls -la "$OUTPUT_DIR" 2>/dev/null | head -10
    fi
    
else
    echo "‚ùå Extraction failed with exit code $EXTRACTION_EXIT_CODE"
    
    if [ -f "${OUTPUT_DIR}/error_log.txt" ]; then
        echo "Error log (last 20 lines):"
        tail -20 "${OUTPUT_DIR}/error_log.txt"
    fi
    
    echo "Troubleshooting:"
    echo "1. Check TAR files integrity"
    echo "2. Try with smaller batch size: --batch_size 2"
    echo "3. Try with fewer GPUs: --world_size 2"
fi

echo "Final GPU Memory Status:"
nvidia-smi --query-gpu=index,name,memory.used,memory.free --format=csv,noheader

echo "Job completed at $(date)"
TOTAL_SECONDS=$(($(date +%s) - $SECONDS))
TOTAL_HOURS=$(echo "scale=2; $TOTAL_SECONDS / 3600" | bc -l)
echo "Total job time: ${TOTAL_HOURS} hours"

exit $EXTRACTION_EXIT_CODE